{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LabeledStatuses_Sandy_K 1 / 19\n",
      "Processing Users_Florence_A 2 / 19\n",
      "Processing Statuses_Maria_A 3 / 19\n",
      "Processing Users_Irma_A 4 / 19\n",
      "Processing Statuses_Irma_C 5 / 19\n",
      "Processing LabeledStatuses_Irma_A_ 6 / 19\n",
      "Processing Statuses_Florence_A 7 / 19\n",
      "Processing LabeledStatuses_Irma_C 8 / 19\n",
      "Processing Misc_MiscFilmReviews_M 9 / 19\n",
      "Processing Statuses_Florence_C 10 / 19\n",
      "Processing Statuses_Irma_A 11 / 19\n",
      "Processing Statuses_MiscPower_A 12 / 19\n",
      "Processing LabeledStatuses_MiscTechCompanies_A 13 / 19\n",
      "Processing Statuses_Maria_C 14 / 19\n",
      "Processing Statuses_MiscClimateChange_A 15 / 19\n",
      "Processing LabeledStatuses_MiscTechCompanies_C 16 / 19\n",
      "Processing Users_Maria_A 17 / 19\n",
      "Processing Statuses_Irma_K 18 / 19\n",
      "Processing LabeledStatuses_Sandy_C 19 / 19\n",
      "  Lat_long                   Source Topic  \\\n",
      "0        |  LabeledStatuses_Sandy_K   NaN   \n",
      "1        |  LabeledStatuses_Sandy_K   NaN   \n",
      "2        |  LabeledStatuses_Sandy_K   NaN   \n",
      "\n",
      "                                           TweetBody TweetDate  \\\n",
      "0  -1 RT @_dreamvillle: On a scale from 1-5 how s...       NaN   \n",
      "1  @jenfromTHEbloc Hi! I have you and all your NY...       NaN   \n",
      "2  #Pakistan Salesforce Social Marketing Cloud Bu...       NaN   \n",
      "\n",
      "                 TweetID TweetId TweetText           UserID  \\\n",
      "0  |\"261938696272629761\"     NaN       NaN           man_EE   \n",
      "1  |\"261964535831871488\"     NaN       NaN  xGrumpyOlTrollx   \n",
      "2  |\"261985749170270208\"     NaN       NaN        22FOURCOM   \n",
      "\n",
      "                        _id  classification         date_time notes  \\\n",
      "0  5c0e7b47d2512c61248b14c5  conversational  10/26/2012 21:13         \n",
      "1  5c0e7b47d2512c61248b14c6  conversational  10/26/2012 22:56         \n",
      "2  5c0e7b47d2512c61248b14c7      irrelevant   10/27/2012 0:20         \n",
      "\n",
      "                       original_file   sentiment text  \n",
      "0  LABELED_DATA/ClassifiedTweets.csv    positive  NaN  \n",
      "1  LABELED_DATA/ClassifiedTweets.csv    positive  NaN  \n",
      "2  LABELED_DATA/ClassifiedTweets.csv  irrelevant  NaN  \n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pd_doc2vec import doc2vec\n",
    "\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "client = MongoClient('da1.eecs.utk.edu', 27017) \n",
    "#Connects to the MongoDB, make sure youre SSH'ed into the docker\n",
    "\n",
    "collection_list = client['twitter'].collection_names() \n",
    "#Scrapes all the collection names from the Docker\n",
    "i =0\n",
    "sentimentdata = []\n",
    "for posts in (collection_list):\n",
    "    i = i+1\n",
    "    print(\"Processing\", posts, i, \"/\", str(len(collection_list)))\n",
    "    for post in client['twitter'][posts].find({'sentiment': {\"$exists\": True}}):  \n",
    "        #Extracts all the entries with a sentiment field\n",
    "        post.update({\"Source\": str(posts)}) \n",
    "        #Updates each data with the name of the collection it comes from\n",
    "        sentimentdata.append(post) \n",
    "\n",
    "df = pd.DataFrame(sentimentdata)\n",
    "# pulls data into the Pandas DataFrame\n",
    "\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lat_long' 'Source' 'Topic' 'TweetBody' 'TweetDate' 'TweetID' 'TweetId'\n",
      " 'TweetText' 'UserID' '_id' 'classification' 'date_time' 'notes'\n",
      " 'original_file' 'sentiment' 'text']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values) #How many Columns we have in our dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Misc_MiscFilmReviews_M                 100000\n",
       "LabeledStatuses_MiscTechCompanies_C      5114\n",
       "LabeledStatuses_Sandy_K                   325\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Source'].value_counts() \n",
    "\n",
    "#How many sources our data comes from,  different sources might label the \n",
    "#same data under different names/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Lat_long                  Source Topic TweetBody TweetDate TweetID  \\\n",
      "91903      NaN  Misc_MiscFilmReviews_M   NaN       NaN       NaN     NaN   \n",
      "86338      NaN  Misc_MiscFilmReviews_M   NaN       NaN       NaN     NaN   \n",
      "58918      NaN  Misc_MiscFilmReviews_M   NaN       NaN       NaN     NaN   \n",
      "68066      NaN  Misc_MiscFilmReviews_M   NaN       NaN       NaN     NaN   \n",
      "\n",
      "      TweetId TweetText UserID                       _id classification  \\\n",
      "91903     NaN       NaN    NaN  5beee7988d75df32fe7cd40a            NaN   \n",
      "86338     NaN       NaN    NaN  5beee7988d75df32fe7cbe4d            NaN   \n",
      "58918     NaN       NaN    NaN  5beee7988d75df32fe7c5331            NaN   \n",
      "68066     NaN       NaN    NaN  5beee7988d75df32fe7c76ed            NaN   \n",
      "\n",
      "      date_time notes original_file sentiment  \\\n",
      "91903       NaN   NaN           NaN  negative   \n",
      "86338       NaN   NaN           NaN  negative   \n",
      "58918       NaN   NaN           NaN  positive   \n",
      "68066       NaN   NaN           NaN  positive   \n",
      "\n",
      "                                                    text  \n",
      "91903  i usually comment only on movies that i like f...  \n",
      "86338  i agree with several of you that this film was...  \n",
      "58918  the beat is too strong we re deaf mutants now ...  \n",
      "68066  i absolutely loved this film i was hesitant to...  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Source'] == 'Misc_MiscFilmReviews_M'].sample(4))\n",
    "\n",
    "# This source contains the text under \"text\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Lat_long                   Source Topic  \\\n",
      "130        |  LabeledStatuses_Sandy_K   NaN   \n",
      "281        |  LabeledStatuses_Sandy_K   NaN   \n",
      "81         |  LabeledStatuses_Sandy_K   NaN   \n",
      "27         |  LabeledStatuses_Sandy_K   NaN   \n",
      "\n",
      "                                             TweetBody TweetDate  \\\n",
      "130  Hope everyone in america stays safe in the sto...       NaN   \n",
      "281  RT @SpittyP: To any and all who were affected ...       NaN   \n",
      "81   @_ashhmoney I hate you. Sandy gon blow my litt...       NaN   \n",
      "27   RT @Tofaial: Hurricane Sandy?  Not even intimi...       NaN   \n",
      "\n",
      "                   TweetID TweetId TweetText       UserID  \\\n",
      "130  |\"263017227308105728\"     NaN       NaN        klw93   \n",
      "281  |\"265082031568982018\"     NaN       NaN       kcluva   \n",
      "81   |\"262921713644367877\"     NaN       NaN  __half_pint   \n",
      "27   |\"262622755701260288\"     NaN       NaN  CuDi_Zoning   \n",
      "\n",
      "                          _id  classification         date_time notes  \\\n",
      "130  5c0e7b47d2512c61248b1547  conversational  10/29/2012 20:39         \n",
      "281  5c0e7b47d2512c61248b15de  conversational   11/4/2012 13:24         \n",
      "81   5c0e7b47d2512c61248b1516  conversational  10/29/2012 14:19         \n",
      "27   5c0e7b47d2512c61248b14e0  conversational  10/28/2012 18:31         \n",
      "\n",
      "                         original_file sentiment text  \n",
      "130  LABELED_DATA/ClassifiedTweets.csv  positive  NaN  \n",
      "281  LABELED_DATA/ClassifiedTweets.csv  positive  NaN  \n",
      "81   LABELED_DATA/ClassifiedTweets.csv  negative  NaN  \n",
      "27   LABELED_DATA/ClassifiedTweets.csv  positive  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Source'] == 'LabeledStatuses_Sandy_K'].sample(4))\n",
    "\n",
    "# This source contains the text under \"TweetBody\" and has a \"classification\"\n",
    "# field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Lat_long                               Source      Topic TweetBody  \\\n",
      "105246      NaN  LabeledStatuses_MiscTechCompanies_C    twitter       NaN   \n",
      "103396      NaN  LabeledStatuses_MiscTechCompanies_C  microsoft       NaN   \n",
      "104773      NaN  LabeledStatuses_MiscTechCompanies_C    twitter       NaN   \n",
      "100928      NaN  LabeledStatuses_MiscTechCompanies_C      apple       NaN   \n",
      "\n",
      "                             TweetDate TweetID             TweetId  \\\n",
      "105246  Thu Oct 20 03:41:03 +0000 2011     NaN  126865487584968704   \n",
      "103396  Wed Oct 19 13:15:07 +0000 2011     NaN  126647567877541889   \n",
      "104773  Thu Oct 20 03:27:19 +0000 2011     NaN  126862030979334144   \n",
      "100928  Tue Oct 18 03:17:50 +0000 2011     NaN  126134865887363072   \n",
      "\n",
      "                                                TweetText UserID  \\\n",
      "105246                                      xau #twitter.    NaN   \n",
      "103396  #Microsoft shows 'touch screen' for any surfac...    NaN   \n",
      "104773  RT @AmySimendinger: @rachiecrewz dude you can'...    NaN   \n",
      "100928        \"#Win an @Apple iPod Touch from @Mommy_gaga    NaN   \n",
      "\n",
      "                             _id classification date_time notes  \\\n",
      "105246  5c0e75e4d2512c60ce527a3b            NaN       NaN   NaN   \n",
      "103396  5c0e75e4d2512c60ce527301            NaN       NaN   NaN   \n",
      "104773  5c0e75e4d2512c60ce527862            NaN       NaN   NaN   \n",
      "100928  5c0e75e4d2512c60ce52695d            NaN       NaN   NaN   \n",
      "\n",
      "                       original_file   sentiment text  \n",
      "105246  LABELED_DATA/full-corpus.csv  irrelevant  NaN  \n",
      "103396  LABELED_DATA/full-corpus.csv     neutral  NaN  \n",
      "104773  LABELED_DATA/full-corpus.csv     neutral  NaN  \n",
      "100928  LABELED_DATA/full-corpus.csv     neutral  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Source'] == 'LabeledStatuses_MiscTechCompanies_C'].sample(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat_long          105114\n",
      "Source                 0\n",
      "Topic                  0\n",
      "TweetBody         105114\n",
      "TweetDate         100327\n",
      "TweetID           105114\n",
      "TweetId           100327\n",
      "TweetText         100327\n",
      "UserID            105114\n",
      "_id                    0\n",
      "classification         0\n",
      "date_time         105114\n",
      "notes             105114\n",
      "original_file     100000\n",
      "sentiment              2\n",
      "text                   2\n",
      "main                   2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df[\"main\"] = df[\"sentiment\"]\n",
    "# we are going to build a main label that is just the sentiment\n",
    "\n",
    "df[\"sentiment\"] = df[\"Source\"] + \"_\" + df[\"sentiment\"]\n",
    "# We add source informationg with the sentiment\n",
    "\n",
    "df['text'].fillna(df['TweetBody'], inplace=True)\n",
    "df['text'].fillna(df['TweetText'], inplace=True)\n",
    "# we move the text from tweetbody into text\n",
    "\n",
    "df['classification'] = df['classification'].fillna(\"unclassified\")\n",
    "df['Topic'] = df['Topic'].fillna(\"no_topic\")\n",
    "#we populate empty classification  fields with \"0\"\n",
    "\n",
    "\n",
    "print(df.isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Source  \\\n",
      "101705  LabeledStatuses_MiscTechCompanies_C   \n",
      "104603  LabeledStatuses_MiscTechCompanies_C   \n",
      "\n",
      "                                                    Topic  \\\n",
      "101705               #google #Nexus http://t.co/CSAeFRHc\"   \n",
      "104603   add yourself for more #twitter followers! net...   \n",
      "\n",
      "                             _id classification sentiment  text  main  \n",
      "101705  5c0e75e4d2512c60ce526c66   unclassified       NaN  None  None  \n",
      "104603  5c0e75e4d2512c60ce5277b8   unclassified       NaN  None  None  \n"
     ]
    }
   ],
   "source": [
    "# We need text as our X and our Y will be main, sentiment, Source, Topic, classification\n",
    "#But as seen above, we have NANs in the main, text, sentiment columns! so we should drop them \n",
    "df = df.drop(['Lat_long', 'TweetBody', 'TweetDate', 'TweetID', 'TweetId', 'TweetText', 'UserID', 'date_time', 'notes', 'original_file'], axis=1)\n",
    "df1 = df[df.isnull().any(axis=1)]\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source            0\n",
      "Topic             0\n",
      "_id               0\n",
      "classification    0\n",
      "sentiment         0\n",
      "text              0\n",
      "main              0\n",
      "dtype: int64\n",
      "                    Source     Topic                       _id  \\\n",
      "0  LabeledStatuses_Sandy_K  no_topic  5c0e7b47d2512c61248b14c5   \n",
      "1  LabeledStatuses_Sandy_K  no_topic  5c0e7b47d2512c61248b14c6   \n",
      "2  LabeledStatuses_Sandy_K  no_topic  5c0e7b47d2512c61248b14c7   \n",
      "\n",
      "   classification                           sentiment  \\\n",
      "0  conversational    LabeledStatuses_Sandy_K_positive   \n",
      "1  conversational    LabeledStatuses_Sandy_K_positive   \n",
      "2      irrelevant  LabeledStatuses_Sandy_K_irrelevant   \n",
      "\n",
      "                                                text        main  \n",
      "0  -1 RT @_dreamvillle: On a scale from 1-5 how s...    positive  \n",
      "1  @jenfromTHEbloc Hi! I have you and all your NY...    positive  \n",
      "2  #Pakistan Salesforce Social Marketing Cloud Bu...  irrelevant  \n"
     ]
    }
   ],
   "source": [
    "#Those dont have any usefull information, we can drop them! \n",
    "df = df.dropna()\n",
    "print(df.isna().sum())\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(str)\n",
    "#To make sure we dont have wierd data types lingering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_topic' 'apple' 'google' 'microsoft' 'twitter']\n",
      "['LabeledStatuses_Sandy_K' 'Misc_MiscFilmReviews_M'\n",
      " 'LabeledStatuses_MiscTechCompanies_C']\n",
      "['conversational' 'irrelevant' 'informational' 'unclassified']\n",
      "['LabeledStatuses_Sandy_K_positive' 'LabeledStatuses_Sandy_K_irrelevant'\n",
      " 'LabeledStatuses_Sandy_K_negative' 'LabeledStatuses_Sandy_K_neutral'\n",
      " 'Misc_MiscFilmReviews_M_positive' 'Misc_MiscFilmReviews_M_negative'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_positive'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_negative'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_neutral'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_irrelevant']\n",
      "['positive' 'irrelevant' 'negative' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# These are the different classifications we can do cosine similarity and check distance on\n",
    "\n",
    "print(df.Topic.unique())\n",
    "print(df.Source.unique())\n",
    "print(df.classification.unique())\n",
    "print(df.sentiment.unique())\n",
    "print(df.main.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'neutral' 'negative']\n"
     ]
    }
   ],
   "source": [
    "df=df.replace('irrelevant', 'neutral') #Combining these will make the accuracy better\n",
    "print(df.main.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting vairables\n",
      "Scoring Model\n",
      "splitting train and test\n",
      "labeling sentences\n",
      "training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "100%|██████████| 5272/5272 [20:31<00:00,  4.68it/s]\n",
      "/home/nwest13/Curent/Manny/pd_doc2vec.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  test['results'] = self.predict(test[X])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring results\n",
      "Label Score: \n",
      "[0.83327568 0.63265306 0.79946285]\n",
      "Accuracy Score: \n",
      "0.8133535660091047\n",
      "Predicting on text\n",
      "['negative', 'Misc_MiscFilmReviews_M', 'Misc_MiscFilmReviews_M_negative', 'unclassified', 'no_topic']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Setting vairables\")\n",
    "\n",
    "# We pass the class 3 fields:\n",
    "# 1. The DataFrame\n",
    "# 2. The X value, the Text (Pandas Series)\n",
    "# 3. The Y values, the labels that correspond to the text (Pandas Series)\n",
    "#                   It can be a list of the names of the columns or one as a string\n",
    "\n",
    "x = doc2vec(df, \"text\", [\"main\",  \"Source\", 'sentiment', 'classification', 'Topic'])\n",
    "\n",
    "print(\"Scoring Model\")\n",
    "\n",
    "#returns scores of each labels accuracy from the first column passed into \n",
    "# the Y or 3 arguments, in this example it was \"main\"\n",
    "# this uses sklearn.metrics.f1_score, you can pass in \n",
    "x.score(verbose=True)\n",
    "\n",
    "print(\"Predicting on text\")\n",
    "\n",
    "# You can predict text as follows\n",
    "print(x.predict_text(\"I dislike old cabin cruisers.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/951 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "100%|██████████| 951/951 [04:25<00:00,  3.19it/s]\n",
      "100%|██████████| 951/951 [00:00<00:00, 1615.00it/s]\n",
      "100%|██████████| 951/951 [00:00<00:00, 2631.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order     ID       Date                                              Tweet  \\\n",
      "0      1   3020  10-Sep-17  @wsvn right below is the parking lot, across f...   \n",
      "1      3  67518  10-Sep-17     @WPTV #HurricanIrma pic.twitter.com/cpStsW3MXx   \n",
      "2      5  20428  10-Sep-17  . @DukeEnergy says 447 people without power in...   \n",
      "3      7  39812  13-Sep-17  So if your regular pickup is on a Tuesday, do ...   \n",
      "4      9  60263  09-Sep-17  4 more shelters opened in Sarasota Co. bringin...   \n",
      "5     10  40013  10-Sep-17  Surprisingly, still got it on Wacahoota Road i...   \n",
      "6     11  36698  10-Sep-17  . @PolkCoSheriff Grady Judd says his deputies ...   \n",
      "7     12  61411  14-Sep-17  @FLGovScott @SenRubioPress has anyone come to ...   \n",
      "8     13  34114  08-Sep-17  Good morning West Palm Beach. Heading to @WPTV...   \n",
      "9     14   2018  04-Sep-17  Gov. Rick Scott urges Floridians to plan for H...   \n",
      "\n",
      "     manual doc2vec_results  \\\n",
      "0   neutral        negative   \n",
      "1   neutral        positive   \n",
      "2   neutral        negative   \n",
      "3   neutral        negative   \n",
      "4   neutral        negative   \n",
      "5  negative        negative   \n",
      "6  positive        negative   \n",
      "7   neutral        negative   \n",
      "8  positive        negative   \n",
      "9  positive        positive   \n",
      "\n",
      "                                             results  \\\n",
      "0  [(unclassified, 0.753822922706604), (Misc_Misc...   \n",
      "1  [(unclassified, 0.6928697824478149), (Misc_Mis...   \n",
      "2  [(unclassified, 0.7349542379379272), (Misc_Mis...   \n",
      "3  [(unclassified, 0.7974395751953125), (Misc_Mis...   \n",
      "4  [(unclassified, 0.7236266732215881), (Misc_Mis...   \n",
      "5  [(unclassified, 0.823154091835022), (Misc_Misc...   \n",
      "6  [(unclassified, 0.7626656293869019), (Misc_Mis...   \n",
      "7  [(unclassified, 0.7803273797035217), (Misc_Mis...   \n",
      "8  [(unclassified, 0.740906834602356), (Misc_Misc...   \n",
      "9  [(unclassified, 0.7085155248641968), (Misc_Mis...   \n",
      "\n",
      "   LabeledStatuses_MiscTechCompanies_C  \\\n",
      "0                             0.399029   \n",
      "1                             0.448392   \n",
      "2                             0.534988   \n",
      "3                             0.391515   \n",
      "4                             0.500327   \n",
      "5                             0.381098   \n",
      "6                             0.409330   \n",
      "7                             0.341489   \n",
      "8                             0.443708   \n",
      "9                             0.517854   \n",
      "\n",
      "   LabeledStatuses_MiscTechCompanies_C_irrelevant  \\\n",
      "0                                        0.385086   \n",
      "1                                        0.431158   \n",
      "2                                        0.528327   \n",
      "3                                        0.385003   \n",
      "4                                        0.487665   \n",
      "5                                        0.385127   \n",
      "6                                        0.401550   \n",
      "7                                        0.348863   \n",
      "8                                        0.416287   \n",
      "9                                        0.520286   \n",
      "\n",
      "   LabeledStatuses_MiscTechCompanies_C_negative    ...          290       291  \\\n",
      "0                                      0.394856    ...     0.082276 -0.089353   \n",
      "1                                      0.424425    ...     0.028376 -0.024000   \n",
      "2                                      0.513083    ...     0.004587 -0.069385   \n",
      "3                                      0.394669    ...    -0.006280 -0.097574   \n",
      "4                                      0.477731    ...     0.006178 -0.086884   \n",
      "5                                      0.358644    ...     0.035607 -0.105978   \n",
      "6                                      0.392489    ...    -0.054521 -0.091819   \n",
      "7                                      0.319552    ...     0.020121 -0.075377   \n",
      "8                                      0.434296    ...     0.073810 -0.086934   \n",
      "9                                      0.461065    ...     0.070890 -0.040190   \n",
      "\n",
      "        292       293       294       295       296       297       298  \\\n",
      "0  0.001808 -0.127242  0.076487 -0.036461 -0.153360  0.033186  0.018269   \n",
      "1  0.010740 -0.063772  0.031653 -0.005436 -0.029339  0.016637  0.010210   \n",
      "2  0.018974 -0.097129  0.058510  0.005691 -0.135696 -0.003626  0.012312   \n",
      "3  0.000153 -0.092828  0.106231 -0.025204 -0.126429  0.022626  0.010677   \n",
      "4  0.033104 -0.081755  0.064405 -0.023950 -0.099289  0.030034  0.038078   \n",
      "5 -0.013681 -0.072582  0.072506 -0.039967 -0.133435  0.018460  0.014078   \n",
      "6  0.037902 -0.128484  0.112049 -0.059804 -0.080399  0.016883  0.024660   \n",
      "7  0.015604 -0.087824  0.061647 -0.036396 -0.062105 -0.006858  0.038633   \n",
      "8  0.025130 -0.111217  0.068600 -0.040747 -0.100211  0.011523  0.068459   \n",
      "9  0.023817 -0.107204  0.100658 -0.058529 -0.179048  0.007611  0.029059   \n",
      "\n",
      "        299  \n",
      "0 -0.076923  \n",
      "1 -0.017182  \n",
      "2 -0.060392  \n",
      "3 -0.019746  \n",
      "4 -0.059346  \n",
      "5 -0.030844  \n",
      "6 -0.002576  \n",
      "7  0.002594  \n",
      "8 -0.058658  \n",
      "9 -0.047000  \n",
      "\n",
      "[10 rows x 332 columns]\n"
     ]
    }
   ],
   "source": [
    "media = pd.read_csv(\"Media_Tweets_1000.csv\") #Tweets we want to clasify\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()  #To do progress_apply, it is pandas .apply but with a progess bar \n",
    "\n",
    "\n",
    "#lets label the media tweets with what the closest doc2vec label is\n",
    "media[\"doc2vec_results\"] = x.predict(media[\"Tweet\"])\n",
    "\n",
    "\n",
    "\n",
    "#now lets add the vector and label distances to each row so we can use randomforrest\n",
    "media[\"results\"] =  media[\"Tweet\"].progress_apply(x.predict_sims)\n",
    "\n",
    "\n",
    "sims_dict = {'apple':[], 'microsoft':[], 'LabeledStatuses_MiscTechCompanies_C_neutral':[], 'LabeledStatuses_MiscTechCompanies_C_irrelevant':[], 'LabeledStatuses_MiscTechCompanies_C_positive':[], 'google':[], 'LabeledStatuses_MiscTechCompanies_C_negative':[], 'twitter':[], 'LabeledStatuses_MiscTechCompanies_C':[], 'neutral':[], 'unclassified':[], 'no_topic':[], 'Misc_MiscFilmReviews_M':[], 'positive':[], 'negative':[], 'Misc_MiscFilmReviews_M_positive':[],'Misc_MiscFilmReviews_M_negative':[],'LabeledStatuses_Sandy_K_positive':[], 'conversational':[], 'LabeledStatuses_Sandy_K':[], 'LabeledStatuses_Sandy_K_irrelevant':[], 'informational':[], 'LabeledStatuses_Sandy_K_neutral':[], 'LabeledStatuses_Sandy_K_negative':[]}\n",
    "\n",
    "\n",
    "\n",
    "for index, row in media.iterrows():\n",
    "    results_list =row[\"results\"]\n",
    "\n",
    "    for i in [i[0] for i in results_list ]:\n",
    "        sims_dict[i].append([rec for rec in results_list if rec[0] == i][0][1])\n",
    "\n",
    "#This will create a dataframe from the dict and then it will be concated to the original\n",
    "#This will add label distances\n",
    "media_df = pd.DataFrame.from_dict(sims_dict)\n",
    "media = pd.concat([media, media_df], axis=1)\n",
    "\n",
    "\n",
    "#This will add the raw vector data to the row, we will need to expand it\n",
    "#to be able to use it with random forrest\n",
    "media[\"vector\"] =  media[\"Tweet\"].progress_apply(x.get_vector)\n",
    "media_df = pd.DataFrame(media[\"vector\"].values.tolist())\n",
    "media = pd.concat([media, media_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print(media.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Order' 'ID' 'Date' 'Tweet' 'manual' 'doc2vec_results' 'results'\n",
      " 'LabeledStatuses_MiscTechCompanies_C'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_irrelevant'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_negative'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_neutral'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_positive' 'LabeledStatuses_Sandy_K'\n",
      " 'LabeledStatuses_Sandy_K_irrelevant' 'LabeledStatuses_Sandy_K_negative'\n",
      " 'LabeledStatuses_Sandy_K_neutral' 'LabeledStatuses_Sandy_K_positive'\n",
      " 'Misc_MiscFilmReviews_M' 'Misc_MiscFilmReviews_M_negative'\n",
      " 'Misc_MiscFilmReviews_M_positive' 'apple' 'conversational' 'google'\n",
      " 'informational' 'microsoft' 'negative' 'neutral' 'no_topic' 'positive'\n",
      " 'twitter' 'unclassified' 'vector' 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      " 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39\n",
      " 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63\n",
      " 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n",
      " 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
      " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n",
      " 289 290 291 292 293 294 295 296 297 298 299]\n"
     ]
    }
   ],
   "source": [
    "print(media.columns.values) #How many Columns we have in our dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 324)\n",
      "(109,)\n"
     ]
    }
   ],
   "source": [
    "media_cleaned = media.drop(['Order', 'ID', 'Date', 'Tweet', 'doc2vec_results', 'doc2vec_results', 'results', 'vector'], axis=1)\n",
    "train_media_cleaned = media_cleaned.dropna()\n",
    "train_mediax = train_media_cleaned.drop(['manual'], axis=1)\n",
    "train_mediay =  train_media_cleaned['manual']\n",
    "\n",
    "#Preparing our train set\n",
    "print(train_mediax.shape)\n",
    "print(train_mediay.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LabeledStatuses_MiscTechCompanies_C'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_irrelevant'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_negative'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_neutral'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_positive' 'LabeledStatuses_Sandy_K'\n",
      " 'LabeledStatuses_Sandy_K_irrelevant' 'LabeledStatuses_Sandy_K_negative'\n",
      " 'LabeledStatuses_Sandy_K_neutral' 'LabeledStatuses_Sandy_K_positive'\n",
      " 'Misc_MiscFilmReviews_M' 'Misc_MiscFilmReviews_M_negative'\n",
      " 'Misc_MiscFilmReviews_M_positive' 'apple' 'conversational' 'google'\n",
      " 'informational' 'microsoft' 'negative' 'neutral' 'no_topic' 'positive'\n",
      " 'twitter' 'unclassified' 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18\n",
      " 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42\n",
      " 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66\n",
      " 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90\n",
      " 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182\n",
      " 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218\n",
      " 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236\n",
      " 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254\n",
      " 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272\n",
      " 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290\n",
      " 291 292 293 294 295 296 297 298 299]\n"
     ]
    }
   ],
   "source": [
    "print(train_mediax.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order     ID       Date                                              Tweet  \\\n",
      "0      1   3020  10-Sep-17  @wsvn right below is the parking lot, across f...   \n",
      "1      3  67518  10-Sep-17     @WPTV #HurricanIrma pic.twitter.com/cpStsW3MXx   \n",
      "2      5  20428  10-Sep-17  . @DukeEnergy says 447 people without power in...   \n",
      "3      7  39812  13-Sep-17  So if your regular pickup is on a Tuesday, do ...   \n",
      "4      9  60263  09-Sep-17  4 more shelters opened in Sarasota Co. bringin...   \n",
      "5     10  40013  10-Sep-17  Surprisingly, still got it on Wacahoota Road i...   \n",
      "6     11  36698  10-Sep-17  . @PolkCoSheriff Grady Judd says his deputies ...   \n",
      "7     12  61411  14-Sep-17  @FLGovScott @SenRubioPress has anyone come to ...   \n",
      "8     13  34114  08-Sep-17  Good morning West Palm Beach. Heading to @WPTV...   \n",
      "9     14   2018  04-Sep-17  Gov. Rick Scott urges Floridians to plan for H...   \n",
      "\n",
      "     manual doc2vec_results  \\\n",
      "0   neutral        negative   \n",
      "1   neutral        positive   \n",
      "2   neutral        negative   \n",
      "3   neutral        negative   \n",
      "4   neutral        negative   \n",
      "5  negative        negative   \n",
      "6  positive        negative   \n",
      "7   neutral        negative   \n",
      "8  positive        negative   \n",
      "9  positive        positive   \n",
      "\n",
      "                                             results  \\\n",
      "0  [(unclassified, 0.753822922706604), (Misc_Misc...   \n",
      "1  [(unclassified, 0.6928697824478149), (Misc_Mis...   \n",
      "2  [(unclassified, 0.7349542379379272), (Misc_Mis...   \n",
      "3  [(unclassified, 0.7974395751953125), (Misc_Mis...   \n",
      "4  [(unclassified, 0.7236266732215881), (Misc_Mis...   \n",
      "5  [(unclassified, 0.823154091835022), (Misc_Misc...   \n",
      "6  [(unclassified, 0.7626656293869019), (Misc_Mis...   \n",
      "7  [(unclassified, 0.7803273797035217), (Misc_Mis...   \n",
      "8  [(unclassified, 0.740906834602356), (Misc_Misc...   \n",
      "9  [(unclassified, 0.7085155248641968), (Misc_Mis...   \n",
      "\n",
      "   LabeledStatuses_MiscTechCompanies_C  \\\n",
      "0                             0.399029   \n",
      "1                             0.448392   \n",
      "2                             0.534988   \n",
      "3                             0.391515   \n",
      "4                             0.500327   \n",
      "5                             0.381098   \n",
      "6                             0.409330   \n",
      "7                             0.341489   \n",
      "8                             0.443708   \n",
      "9                             0.517854   \n",
      "\n",
      "   LabeledStatuses_MiscTechCompanies_C_irrelevant  \\\n",
      "0                                        0.385086   \n",
      "1                                        0.431158   \n",
      "2                                        0.528327   \n",
      "3                                        0.385003   \n",
      "4                                        0.487665   \n",
      "5                                        0.385127   \n",
      "6                                        0.401550   \n",
      "7                                        0.348863   \n",
      "8                                        0.416287   \n",
      "9                                        0.520286   \n",
      "\n",
      "   LabeledStatuses_MiscTechCompanies_C_negative     ...           291  \\\n",
      "0                                      0.394856     ...     -0.089353   \n",
      "1                                      0.424425     ...     -0.024000   \n",
      "2                                      0.513083     ...     -0.069385   \n",
      "3                                      0.394669     ...     -0.097574   \n",
      "4                                      0.477731     ...     -0.086884   \n",
      "5                                      0.358644     ...     -0.105978   \n",
      "6                                      0.392489     ...     -0.091819   \n",
      "7                                      0.319552     ...     -0.075377   \n",
      "8                                      0.434296     ...     -0.086934   \n",
      "9                                      0.461065     ...     -0.040190   \n",
      "\n",
      "        292       293       294       295       296       297       298  \\\n",
      "0  0.001808 -0.127242  0.076487 -0.036461 -0.153360  0.033186  0.018269   \n",
      "1  0.010740 -0.063772  0.031653 -0.005436 -0.029339  0.016637  0.010210   \n",
      "2  0.018974 -0.097129  0.058510  0.005691 -0.135696 -0.003626  0.012312   \n",
      "3  0.000153 -0.092828  0.106231 -0.025204 -0.126429  0.022626  0.010677   \n",
      "4  0.033104 -0.081755  0.064405 -0.023950 -0.099289  0.030034  0.038078   \n",
      "5 -0.013681 -0.072582  0.072506 -0.039967 -0.133435  0.018460  0.014078   \n",
      "6  0.037902 -0.128484  0.112049 -0.059804 -0.080399  0.016883  0.024660   \n",
      "7  0.015604 -0.087824  0.061647 -0.036396 -0.062105 -0.006858  0.038633   \n",
      "8  0.025130 -0.111217  0.068600 -0.040747 -0.100211  0.011523  0.068459   \n",
      "9  0.023817 -0.107204  0.100658 -0.058529 -0.179048  0.007611  0.029059   \n",
      "\n",
      "        299  rf_results  \n",
      "0 -0.076923     neutral  \n",
      "1 -0.017182     neutral  \n",
      "2 -0.060392     neutral  \n",
      "3 -0.019746     neutral  \n",
      "4 -0.059346     neutral  \n",
      "5 -0.030844    negative  \n",
      "6 -0.002576    positive  \n",
      "7  0.002594     neutral  \n",
      "8 -0.058658    positive  \n",
      "9 -0.047000    positive  \n",
      "\n",
      "[10 rows x 333 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_mediax, train_mediay)\n",
    "media[\"rf_results\"] = clf.predict(media_cleaned.drop(['manual'], axis=1))\n",
    "print(media.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Order' 'ID' 'Date' 'Tweet' 'manual' 'doc2vec_results' 'results'\n",
      " 'LabeledStatuses_MiscTechCompanies_C'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_irrelevant'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_negative'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_neutral'\n",
      " 'LabeledStatuses_MiscTechCompanies_C_positive' 'LabeledStatuses_Sandy_K'\n",
      " 'LabeledStatuses_Sandy_K_irrelevant' 'LabeledStatuses_Sandy_K_negative'\n",
      " 'LabeledStatuses_Sandy_K_neutral' 'LabeledStatuses_Sandy_K_positive'\n",
      " 'Misc_MiscFilmReviews_M' 'Misc_MiscFilmReviews_M_negative'\n",
      " 'Misc_MiscFilmReviews_M_positive' 'apple' 'conversational' 'google'\n",
      " 'informational' 'microsoft' 'negative' 'neutral' 'no_topic' 'positive'\n",
      " 'twitter' 'unclassified' 'vector' 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      " 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39\n",
      " 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63\n",
      " 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n",
      " 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
      " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n",
      " 289 290 291 292 293 294 295 296 297 298 299 'rf_results']\n"
     ]
    }
   ],
   "source": [
    "print(media.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_final = media[['Order', 'ID', 'Date', 'Tweet', 'manual', 'doc2vec_results', 'rf_results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec\n",
      "Label Score: \n",
      "[0.54814815 0.09090909 0.15384615]\n",
      "Accuracy Score: \n",
      "0.3853211009174312\n",
      "Confusion matrix:\n",
      "[[37  1  4]\n",
      " [33  2  6]\n",
      " [23  0  3]]\n",
      "====-=++=+++++=======+==+==========+++++==+++===++++===+++==+++===++\n",
      "RandomForrest\n",
      "Label Score: \n",
      "[1. 1. 1.]\n",
      "Accuracy Score: \n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[42  0  0]\n",
      " [ 0 41  0]\n",
      " [ 0  0 26]]\n"
     ]
    }
   ],
   "source": [
    "media_score = media.dropna()\n",
    "from sklearn.metrics import f1_score,  confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Doc2Vec\")\n",
    "print(\"Label Score: \")\n",
    "print(f1_score(media_score['manual'], media_score['doc2vec_results'], average=None))  # Uses train test split to get score\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(media_score['manual'], media_score['doc2vec_results']))  \n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(media_score['manual'], media_score['doc2vec_results']))  \n",
    "\n",
    "print(\"====-=++=+++++=======+==+==========+++++==+++===++++===+++==+++===++\")\n",
    "print(\"RandomForrest\")\n",
    "print(\"Label Score: \")\n",
    "print(f1_score(media_score['manual'], media_score['rf_results'], average=None))  # Uses train test split to get score\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(media_score['manual'], media_score['rf_results']))  \n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(media_score['manual'], media_score['rf_results']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_final.to_csv(\"Media_Tweets_1000_bothresults.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "media.to_csv(\"Media_Tweets_1000_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('behalf', 0.2262553870677948), ('inferiority', 0.22282403707504272), ('braedonrice', 0.22031021118164062), ('assorted', 0.22029951214790344), ('diabolik', 0.21915343403816223), ('kirkwood', 0.2182234674692154), ('befriending', 0.21771174669265747), ('raining', 0.21722975373268127), ('reduce', 0.21531358361244202), ('rollers', 0.21437782049179077)]\n"
     ]
    }
   ],
   "source": [
    "print(x.model.most_similar('happy', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to save model from https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "fname = get_tmpfile(\"/home/nwest13/Curent/Manny/my_doc2vec_model\")\n",
    "x.model.save(fname)\n",
    "x.model = Doc2Vec.load(fname)  # you can continue training with the loaded model!\n",
    "\n",
    "# If you’re finished training a model (=no more updates, only querying, reduce memory usage), you can do:\n",
    "\n",
    "# x.model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
